{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Natural Language Processing with TensorFlow**\n",
        "\n",
        "- NLP problems are also called **Sequence Problems** because data is presented in a Sequence.\n",
        "\n",
        "Natural Language covers\n",
        "- Text (Such as email, blog post, book, Tweet)\n",
        "- Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)\n",
        "\n",
        "- One **use case** is to scan an incoming emails to see if they are spam or not (classification)\n",
        "- Another **use case** is analyzing feedback complaints to find which segment of business it is talking about\n",
        "\n",
        "**Both of the above are referred to as *sequences*. You might come across terms like **seq2seq**, in other words, finding information in one sequence to produce another sequence.**\n",
        "\n",
        "A typical workflow in NLP is\n",
        "\n",
        "*Text --> Turn into numbers --> Build a model --> Train the model --> use patterns to make predictions*"
      ],
      "metadata": {
        "id": "YTpvVv5d9NZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What we are going to cover**\n",
        "\n",
        "- Getting data\n",
        "- Visualizing text\n",
        "- Converting text into numbers using tokenization\n",
        "- Turning our tokenized text into embedding\n",
        "- Modelling a text dataset\n",
        "    - Starting with a baseline (TF-IDF)\n",
        "    - Building deep learning models like\n",
        "       - LSTM, GRU, Conv1D, Transfer Learning\n",
        "- Comparing the performance of each of our models\n",
        "- Combining the models into **ensemble**\n",
        "- Saving and Loading a **Trained Model**\n",
        "- Find the most wrong predictions\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0hu-w51CAqzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the Helper Functions**"
      ],
      "metadata": {
        "id": "V-gC9kZUDPrX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEcRB2zX9DnA",
        "outputId": "b694b34f-cee3-43d9-f130-c4f891417100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 11:07:12--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-09 11:07:12 (29.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the helper functions**"
      ],
      "metadata": {
        "id": "rP5oxTCTDLoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "i-dzB8i8C4Az"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the Text Dataset**\n",
        "\n",
        "We will be using **Real or Not** dataset from **Kaggle** which contains **text-based Tweets** about natural disasters\n",
        "\n",
        "\n",
        "The Real Tweets are actually about disasters, for example:\n",
        "\n",
        "*Jetstar and Virgin forced to cancel Bali flights again because of ash from Mount Raung volcano*\n",
        "\n",
        "\n",
        "The Not Real Tweets are Tweets not about disasters (they can be on anything), for example:\n",
        "\n",
        "*Education is the most powerful weapon which you can use to change the world.Nelson #Mandela #quote*\n"
      ],
      "metadata": {
        "id": "A7fViM_vDIcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugC38FYvC326",
        "outputId": "08d9c605-9043-4530-a45e-a7e9bb9a6023"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-09 11:07:17--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.125.207, 173.194.64.207, 209.85.200.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.125.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2025-10-09 11:07:17 (133 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unzipping Files**\n",
        " By Unzipping we get the following files\n",
        " - **sample_submission.csv:-** An example of the file that you would submit to Kaggle competition\n",
        " - **train.csv:-** training samples of real and not real disaster Tweets\n",
        " - **test.csv:-** testing samples of real and not real disaster Tweets\n"
      ],
      "metadata": {
        "id": "LafDT3j_FPyB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Visualizing a Text Dataset**"
      ],
      "metadata": {
        "id": "aUc5IncOHZ4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"train.csv\")\n",
        "test_df = pd.read_csv(\"test.csv\")\n",
        "train_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qRVIkw3bC3vR",
        "outputId": "9d01d043-05ef-49ae-af50-1aa4e67ae345"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e62c3b7-5b41-4e36-abb7-4583c34bcc04\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e62c3b7-5b41-4e36-abb7-4583c34bcc04')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1e62c3b7-5b41-4e36-abb7-4583c34bcc04 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1e62c3b7-5b41-4e36-abb7-4583c34bcc04');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8a05a15b-b08e-4b5f-bbc2-ba9945ff2e2f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8a05a15b-b08e-4b5f-bbc2-ba9945ff2e2f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8a05a15b-b08e-4b5f-bbc2-ba9945ff2e2f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          3796,\n          3185,\n          7769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"Oklahoma\",\n          \"Starling City\",\n          \"Trinidad and Tobago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"Three Homes Demolished in Unrecognized Arab Village - International Middle East Media Center http://t.co/ik8m4Yi9T4\",\n          \"Reid Lake fire prompts campground evacuation order http://t.co/jBODKM6rBU\",\n          \"FAAN orders evacuation of abandoned aircraft at MMA http://t.co/dEvYbnVXGQ via @todayng\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "# shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "MSX2HZNcC3sj",
        "outputId": "6b99a187-cea1-48a3-a923-ba282c8864e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-00ccdab6-7849-452e-8d89-b4f3e377e958\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-00ccdab6-7849-452e-8d89-b4f3e377e958')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-00ccdab6-7849-452e-8d89-b4f3e377e958 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-00ccdab6-7849-452e-8d89-b4f3e377e958');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3a8c392f-ea46-43e2-8a86-b1f34849ad4d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3a8c392f-ea46-43e2-8a86-b1f34849ad4d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3a8c392f-ea46-43e2-8a86-b1f34849ad4d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df_shuffled",
              "summary": "{\n  \"name\": \"train_df_shuffled\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          7061,\n          843,\n          10603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"blazing\",\n          \"emergency\",\n          \"rescue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"617-BTOWN-BEATDOWN\",\n          \"Newcastle Upon Tyne, England\",\n          \"Federal Capital Territory\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"This week first responders and DART members are participating in a four day intensive Technical Large Animal... http://t.co/tL93AOd3ER\",\n          \"My mom is watching a show about bridges breaking/falling and the people on them drowning in their cars aka one of my biggest fears ????\",\n          \"@NickLee8  i went to school in a bombed out East End of London3 families to one house no bathroom outside loo &amp; poor so whats yr point\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the **training data** we have a **target** column and from the analysis of the text we will try to predict the **target** column.\n",
        "The **test dataset** does not have a **target** column.\n",
        "\n",
        "Inputs (text column) -> Machine Learning Algorithm -> Outputs (target column)"
      ],
      "metadata": {
        "id": "0mENb5G6IR4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1ldkYOkfC3pB",
        "outputId": "2b8cfb31-39f5-4444-ae22-08999c5f6b41"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9ff424a-71c3-4e43-b8fa-bf5ce7762027\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9ff424a-71c3-4e43-b8fa-bf5ce7762027')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9ff424a-71c3-4e43-b8fa-bf5ce7762027 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9ff424a-71c3-4e43-b8fa-bf5ce7762027');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e94abdb8-8652-4cfd-9c6f-1893516c742a\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e94abdb8-8652-4cfd-9c6f-1893516c742a')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e94abdb8-8652-4cfd-9c6f-1893516c742a button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 3263,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3146,\n        \"min\": 0,\n        \"max\": 10875,\n        \"num_unique_values\": 3263,\n        \"samples\": [\n          8051,\n          425,\n          1330\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1602,\n        \"samples\": [\n          \"UAE\",\n          \"Tokio / Tokyo\",\n          \"Texas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3243,\n        \"samples\": [\n          \"Latest: USA: Huge sinkhole swallows up Brooklyn intersection http://t.co/vspKHg3nZy\",\n          \"I liked a @YouTube video http://t.co/a5YTAw9Vih S.O.S. Rona Guide - The Red Whirlwind\",\n          \"HitchBot travels Europe and greeted with open arms. Gets destroyed after two weeks in america. There's a lesson to be learned here.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "G_I0n1tAC3l_",
        "outputId": "4db03d01-35c4-49fe-cc2e-09fe27581924"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    4342\n",
              "1    3271\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3271</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So,from the above we can easily deduce that we are dealing with a **binary classification** problem.\n",
        "Also, the dataset is fairly balanced with 60% negative class and 40% positive class\n",
        "\n",
        "Where,\n",
        "- 1 = a real disaster Tweet\n",
        "- 0 = not a real disaster Tweet"
      ],
      "metadata": {
        "id": "HkImk9ObUa20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples total?\n",
        "print(f\"Total training samples: {len(train_df)}\")\n",
        "print(f\"Total test samples: {len(test_df)}\")\n",
        "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKf_UdesT5WI",
        "outputId": "cb8df6cb-c70d-4aba-cdac-ae09b3e7eb2e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training samples: 7613\n",
            "Total test samples: 3263\n",
            "Total samples: 10876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train/Test Split**\n",
        "We have got abundance of testing samples and normally a 80/20 split is recommended.\n",
        "\n",
        "**Question:** Why visualize random samples? You could visualize samples in order but this could lead to only seeing a certain subset of data. Better to visualize a substantial quantity (100+) of random samples to get an idea of the different kinds of data you're working with. In machine learning, never underestimate the power of randomness."
      ],
      "metadata": {
        "id": "bD-S-BjAVMGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "\n",
        "'''\n",
        "train_df_shuffled[['text','target']]: Get only the \"text\" and \"target\" column\n",
        "[random_index:random_index+5]: Get only five rows starting from the random index\n",
        ".itertuples(): Iterate over the rows as namedtuples.\n",
        "The return is a named tuple like\n",
        "Pandas(Index=100, text=\"Fire in the building\", target=1)\n",
        "Pandas(Index=101, text=\"Lovely weather today\", target=0)\n",
        "We get these results in the row variable\n",
        "_: is used to get the index\n",
        "text: is used to get the text\n",
        "target: is used to get the target (0 or 1)\n",
        "'''\n",
        "\n",
        "\n",
        "for row in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G-_z6vET5OG",
        "outputId": "b42bf26b-1af6-44e8-9c74-80f68c573f8e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "The majority of those killed were civilians on the ground after the jet first bombed the city's main street then dramatically plummeted\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@NEPD_Loyko Texans hope you are wrong. Radio in Houston have him as starter after Foster injury\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Even then our words slip and souls coincide Finer than subatomic spells Just as we collide http://t.co/2WcbrgN62J\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Maj Muzzamil Pilot Offr of MI-17 crashed near Mansehra today. May Almighty give strength to family to bear the loss http://t.co/EI1K01zAb3\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Ignition Knock (Detonation) Sensor-Senso Standard KS57 http://t.co/bzZdeDcthL http://t.co/OQJNUyIBxM\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split data into Training and Validation Sets**\n",
        "\n",
        "- The test data has no **labels** and we need a way to evaluate the model, so we split the **training data** into **training data** and **validation set.**\n",
        "- Model trains on **training data** and the performances are checked using unseen **validation set.**"
      ],
      "metadata": {
        "id": "6s4RTaABuUw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "'''\n",
        "Each column is converted to a numpy array.\n",
        "train_df_shuffled[\"text\"] is a Pandas Series\n",
        "(basically a 1-D labeled array with an index).\n",
        "Scikit-learn functions like train_test_split are designed to work with\n",
        "NumPy arrays or plain Python lists.\n",
        "Even if you sends a Pandas Series directly, it works too because Pandas is\n",
        "compitable with NumPy but internally scikit-learn will convert it to\n",
        "Numpy anyway\n",
        "'''\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)\n"
      ],
      "metadata": {
        "id": "MEIjZRg6T5Fe"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNjl9AfxT49e",
        "outputId": "01092ebb-ce05-4281-e5b9-82b772d655fb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQbewyYVT40t",
        "outputId": "472cf0a8-7e81-446d-89cc-d639857283cc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object),\n",
              " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a **training and test set**."
      ],
      "metadata": {
        "id": "fauKDF2cxaSb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting Text into Numbers**\n",
        "\n",
        "- We now have **training set and validation set** containing Tweets and Labels\n",
        "\n",
        "**Question:** What is the most important step before we can use a **machine learning algorithm** with our text data?\n",
        "\n",
        "**Answer** Turn the text into numbers.\n",
        "\n",
        "*For any Machine Learning algorithm, the inputs needs to be in numerical form.*\n",
        "\n",
        "In NLP, there are two main concepts of turning text into numbers\n",
        "\n",
        "- **Tokenization:** A straight mapping from a word/character/sub-word to a numerical value. There are three main levels of tokenization\n",
        "   - Using **word-level tokenization** with the sentence like \"I love NLP\" might result in \"I\" being \"0\", \"love\" being \"1\" and \"NLP\" being \"2\". Every word in the **sequence** is considered a single **token**\n",
        "   - **Character Level Tokenization** Converting the letters A-Z to value *1-26* and each character in the sequence is considered a single **token**\n",
        "   - **Sub-word tokenization** is between **word-level** and **character level** tokenization. It involves word into smaller parts and then converting those smaller parts to numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After this these **sub-words** are converted to numerical form.\n",
        "\n",
        "- **Embeddings-** An embedding is a representation of natural language which can be learned. The **representation** is in the form of **feature vector**.For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "  - **Create your own embedding** Once your text has been turned into numbers (required for embedding), you can put them through an **embedding layer** such as **tf.keras.layers.Embedding** and an embedding representation will be learned during model training\n",
        "  - **Reuse pre-learned embedding** Many pre-trained embeddings exist online. These **pre-trained** embeddings have often learned on large corpuses of text and thus have a good **underlying representation of natural language.** We can use **pre-trained embedding** to initialize our model and later on **fine-tune** it to our own specific task.\n",
        "\n",
        "  Regarding **which level of tokenization should one use** mostly depends on your problem. You can try character-level/word level tokenization/embedding and which one performs best should be the choice.\n"
      ],
      "metadata": {
        "id": "NReHJUGCxfsX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Vectorization (tokenization)**\n",
        "\n",
        "Creating *tokens* is the most important step. To tokenize our text, we will use the following\n",
        "**tf.keras.layers.experimental.preprocessing.TextVectorization**\n",
        "\n",
        "The **TextVectorization** layer takes the following parameters as input\n",
        "\n",
        "- **max_tokens:-** Maximum number of words in your vocabulary (e.g. 20,000 or the *number of unique words or text*). It also includes **OOV (out of vocabulary)** tokens\n",
        "- **standardize:-** Method for standardizing text. Default is **lower_and_strip_punctuation** which lowers text and removes all punctuation marks.\n",
        "- **split:-** Text splitting, default is **whitespace** which splits text on spaces\n",
        "- **output_mode:-** How to output tokens, can be **int (integer mapping)**, **binary (one hot encoding)**, count or **tf-idf**\n",
        "- **output_sequence_length:-** Length of tokenized sequence to output. For example, if *output_sequence_length=150*, all tokenized sequences will be **150 tokens long.**\n",
        "- **pad_to_max_tokens:-** Defaults to *False*, If *True*, then all the output feature axis will be padded to *max_tokens* even if the *number of unique tokens* in vocabulary is less than *max_tokens.*\n"
      ],
      "metadata": {
        "id": "v-DT18RMO7M4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization variables\n",
        "text_vectorizer = TextVectorization(\n",
        "                                    max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                    split=\"whitespace\", # how to split tokens\n",
        "                                    ngrams=None, # create groups of n-words?\n",
        "                                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                                    output_sequence_length=None\n",
        "                                    ) # how long should the output sequence of tokens be?\n",
        "                                    # pad_to_max_tokens=True) # Not valid if using max_tokens=None\n",
        "\n"
      ],
      "metadata": {
        "id": "yXXPzn3bwxXS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **TextVectorizaiton** object has been initialized with default settings but let's customize it a little.\n",
        "\n",
        "- We will particulary customize **max_tokens** and **output_sequence_length** variables\n",
        "\n",
        "- The **max_tokens**(number of words in vocabulary) is normally multiple of 10,000, 20,000 and 30,000. For our case we will use **10,000**\n",
        "\n",
        "The **output_sequence_length** will be the average number of tokens per Tweet in the training set.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-uXDTyMDfG6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The code snipet loops over each sentence in 'train_sentences'.\n",
        "Splits the sentence based on whitespace\n",
        "Finds the length of that sentence and keep it in a list\n",
        "we get a list like [5,3,7,2.....].\n",
        "Then, it sums the and divide by the toal number of sentence.\n",
        "\n",
        "Finally, we get the average length of output sequence\n",
        "\n",
        "'''\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axAtkWPewxLQ",
        "outputId": "db0d1197-90e4-42b3-ccf9-1d9f23d1f2eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_length = 10000\n",
        "# max number of words to have in our vocabulary\n",
        "max_length = 15\n",
        "''' max length our sequences will be (e.g. how many words from a\n",
        "    Tweet does our model see?)'''\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "__XjBVQQwxAx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Data Mapping**\n",
        "**Text Vectorizer** is a special layer which learns **how to turn text(words) into numbers**\n",
        "\n",
        "**What .adapt(train_sentences) does**\n",
        "\n",
        "The **.adapt()** step is where the text_vectorizer actually learns the vocabulary.\n",
        "It scans through all your **training sentences** to figure out **which words exist** and **how often they appear.**\n",
        "\n",
        "For example,\n",
        "\n",
        "train_sentences = [\"I love pizza\", \"Pizza is delicious\", \"I hate cold pizza\"]\n",
        "\n",
        "- the .adapt() will read all those sentences\n",
        "- build a vocabulary: A dictionary of all unique words like\n",
        "\n",
        "['[PAD]', '[UNK]', 'pizza', 'i', 'love', 'is', 'delicious', 'hate', 'cold']\n",
        "\n",
        "It then assigns an integer number to each word.\n",
        "\n",
        "'pizza' → 2\n",
        "'i' → 3\n",
        "'love' → 4\n",
        "'is' → 5\n",
        "...\n",
        "\n",
        "Now, whenever you pass a new sentence to **text_vectorizer** it converts it automatically into a **sequence of numbers**\n",
        "\n",
        "text_vectorizer([\"I love pizza\"])  ➜  [[3, 4, 2]]\n"
      ],
      "metadata": {
        "id": "AK6z6oRxXjbF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "gdkxrfEwdqKq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now **training data** is mapped. Let's try the **text_vectorizer** on a customer sentence."
      ],
      "metadata": {
        "id": "L8xUxYjGZsQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVX4yQFAdqHK",
        "outputId": "c00752e5-62c0-41e6-d732-edde5472da32"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our **text** has been converted into **numbers**.\n",
        "- Notice the 0's at the end of the returned tensor because we have set the output length to **15** and any sequence we input will be ouput in a length of **15**."
      ],
      "metadata": {
        "id": "4k4D6KKnap-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqB3W6cLdqEa",
        "outputId": "0c91384f-7038-4a14-be59-612896b025c2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "It was finally demolished in the spring of 2013 and the property has sat vacant since. The justÛ_: saddlebrooke... http://t.co/b8n6e4rYvZ      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  15,   23,  852,  606,    4,    2, 1110,    6, 1336,    7,    2,\n",
              "         927,   41, 2721, 2622]])>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the **get_vocabulary()** function"
      ],
      "metadata": {
        "id": "QCZH-_tEfvPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5]\n",
        "bottom_5_words = words_in_vocab[-5:]\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vN7YN6qdqBU",
        "outputId": "e58ad8c3-fafb-4ed3-f882-290138852716"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', np.str_('the'), np.str_('a'), np.str_('in')]\n",
            "Bottom 5 least common words: [np.str_('pages'), np.str_('paeds'), np.str_('pads'), np.str_('padres'), np.str_('paddytomlinson1')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating an Embedding using an Embedding Layer**\n",
        "\n",
        "- We now have a way of **mapping text to numbers**. We will go a step further and turn those **numbers into an embedding**\n",
        "\n",
        "But why **Embedding is a necessary step**\n",
        "\n",
        "- After the **vectorization layer** our text sentences become something like\n",
        "'I love pizza' ==> [4,6,2,0,0]. These are just word ID's, simple integer but here is the problem, nothing can be deduced from these **numbers**. We cannot deduce things like **pizza and burger** are similar and that **pizza** and **table** are not similar\n",
        "\n",
        "It just sees different integers — like seeing phone numbers:\n",
        "\n",
        "pizza = 125\n",
        "burger = 89\n",
        "table = 500\n",
        "\n",
        "There is no relationship between these numbers.\n",
        "\n",
        "**Enter the Embedding Layer**\n",
        "\n",
        "- The embedding layer gives meaning to those numbers. It takes each **word ID** and converts it into a **dense vector of real numbers** a small list of numbers that represents what the word means in context.\n",
        "Word ID → Embedding Vector\n",
        "2 (“pizza”)  → [0.12, -0.45, 0.88, 0.33, -0.02]\n",
        "\n",
        "6 (“love”)   → [0.91,  0.11, 0.55, -0.23, 0.70]\n",
        "\n",
        "4 (“I”)      → [0.02, -0.09, 0.30,  0.45, 0.10]\n",
        "\n",
        "Now, instead of just having [4, 6, 2],\n",
        "your sentence becomes something like:\n",
        "\n",
        "[\n",
        " [0.02, -0.09, 0.30, 0.45, 0.10],\n",
        "\n",
        " [0.91,  0.11, 0.55, -0.23, 0.70],\n",
        "\n",
        " [0.12, -0.45, 0.88, 0.33, -0.02]\n",
        "]\n",
        "\n",
        "**Why is this powerful**\n",
        "The embeddings help the model understand relationships between words:\n",
        "\n",
        "- \"king\" and \"queen\" have similar vectors and differ mostly by gender dimensions\n",
        "\n",
        "- \"pizza\" and \"burger\" appear in similar food contexts, so their vectors are close\n",
        "\n",
        "\n",
        "Embeddings also **reduce dimensionality**. Embedding converts each word into a small vector like 16, 32, 128\n",
        "\n",
        "Embeddings are learned during training and you do not have to define the relationships yourself.\n",
        "\n",
        "**Analogy:**\n",
        "\n",
        "Think of it like this:\n",
        "\n",
        "**Vectorization =** giving every word a roll number (just an ID).\n",
        "\n",
        "**Embedding =** giving every student (word) a personality profile —\n",
        "strengths, weaknesses, interests (numbers that describe meaning).\n",
        "\n",
        "\n",
        "TextVectorization\n",
        "Turns text into word IDs\n",
        "“I love pizza” → [4, 6, 2]\n",
        "\n",
        "Embedding\n",
        "Turns word IDs into meaning-rich vectors\n",
        "[4, 6, 2] → [[0.02, -0.09, 0.30...], ...]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N0e0jplYgFfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating an Embedding Layer Using an Embedding Layer**\n",
        "\n",
        "- As discussed above the **powerful thing about embeddings** is that it can be learned during training. So, **a model** rather than going through static numbers like **1=1, 2=2**, a word's numeric representation can be improved as the model goes through data samples.\n",
        "\n",
        "*We will see what an embedding layer looks like by using the **tf.keras.layers.Embedding** layer*\n",
        "\n",
        "\n",
        "The main parameters we are concerned about here are:\n",
        "\n",
        "- **input_dim -** The size of vocabulary (e.g. len(text_vectorizer.get_vocabulary() ).\n",
        "- **output_dim -** The size of the **output embedding vector**, for example, a value of **100** outputs a feature vector of **size 100 for each word.**\n",
        "- **embeddings_initializer -** How to initialize embedding matrix, default is **uniform** which randomly initializes embedding matrix with **uniform distribution.** This can be changed by using **pre-learned embeddings.**\n",
        "- **input_length -** Length of sequences being passed to *embedding layer.*\n",
        "\n"
      ],
      "metadata": {
        "id": "xfPLf3bflhJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize\n",
        "                             input_length=max_length, # how long is each input\n",
        "                             name=\"embedding_1\")\n",
        "\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW-Fu6W6dp93",
        "outputId": "6f468619-f846-4e09-d7e8-1393a3a4215e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Embedding name=embedding_1, built=False>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJG0pTdjdp6q",
        "outputId": "76b35f91-33e2-49d6-98f9-ab8859474913"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "@smallforestelf Umm because a gun stopped the gunman with who was carrying a bomb!      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.02692438,  0.00451346, -0.01685288, ..., -0.00061289,\n",
              "          0.0050822 , -0.04684842],\n",
              "        [ 0.02526628,  0.01787874, -0.01643982, ..., -0.0060253 ,\n",
              "          0.01488583, -0.02433949],\n",
              "        [ 0.03143467,  0.02759944,  0.03550751, ..., -0.03582587,\n",
              "         -0.00115436, -0.046015  ],\n",
              "        ...,\n",
              "        [-0.01401442, -0.01166731, -0.03310205, ...,  0.0241088 ,\n",
              "         -0.02523102, -0.04639594],\n",
              "        [-0.03721518, -0.00669315, -0.02011895, ...,  0.03867329,\n",
              "         -0.02918214,  0.01138765],\n",
              "        [-0.02670651,  0.03277263, -0.02580332, ..., -0.04259557,\n",
              "          0.03003252, -0.00745965]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedded version:\n",
        "<tf.Tensor: shape=(1, 15, 128)>\n",
        "\n",
        "- **1:** here is the batch. Hence, we have a single sentence, so it is 1.\n",
        "- **15:** This represents the sequence length (the number of word positions the model expects per sentence). This means that each **sentence is 15 words long**. If the **sentence is shorter** then **tensorflow pads it.**\n",
        "- **128:** This is the **embedding dimension** - the number of numbers used to represent each word's meaning.\n",
        "\n",
        "Embedding(input_dim=vocab_size, output_dim=128)\n",
        "\n",
        "This means that *Each word(or token) will be represented by **128 floating-point numbers** that capture its semantic meaning - how it related to other words.\n",
        "\n",
        "So the tensor shape (1, 15, 128) means:\n",
        "\n",
        "“We have 1 sentence, which is **15 tokens long,** and **each token is represented by 128 features** that capture its meaning.”\n",
        "\n",
        "Word     Feature1            Feature2               Feature128\n",
        "\n",
        "she\t     0.01\t              -0.02\t...  \t            0.03\n",
        "\n",
        "keep\t  -0.04\t               0.05\t...               0.01\n",
        "\n",
        "it\t     0.03\t              -0.01\t...\t              0.02\n",
        "\n",
        "wet\t    -0.07\t              0.02\t...\t              0.04\n",
        "\n",
        "like\t   0.05\t              0.01\t...\t             -0.06\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TMnNlYIQq2QX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Each token in the sentence gets turned into a length of 128-feature vector**"
      ],
      "metadata": {
        "id": "cJQ-o0j9tf72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64ZWy7_Ebeya",
        "outputId": "6bff9e5f-1d74-42ea-ab64-37512380a4e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([ 2.6924375e-02,  4.5134649e-03, -1.6852878e-02, -1.3054766e-02,\n",
              "        1.2090482e-02,  1.8951464e-02,  6.9807768e-03, -2.3053348e-02,\n",
              "       -2.2919655e-02,  3.5134520e-02,  4.5245077e-02,  3.4086559e-02,\n",
              "        4.6049122e-02, -3.1613886e-02, -7.4185021e-03, -1.7319538e-02,\n",
              "        8.7212771e-05, -3.7154663e-02,  3.5107542e-02,  1.3365459e-02,\n",
              "        3.0832402e-03, -8.5102208e-03, -2.5723541e-02, -2.4223639e-02,\n",
              "        3.8212802e-02,  3.4688581e-02, -2.9946422e-02, -4.9709786e-02,\n",
              "       -2.6710952e-02, -9.5573552e-03,  2.9594254e-02, -4.9265575e-02,\n",
              "       -2.3818128e-03, -1.2318648e-02, -4.1492641e-02, -2.7676001e-03,\n",
              "       -4.6026219e-02, -1.8073402e-02,  3.6907684e-02,  3.5456154e-02,\n",
              "        1.1080660e-02, -8.0083497e-03, -4.6619713e-02, -1.9938529e-02,\n",
              "        3.8194302e-02,  9.6670873e-03, -2.8421164e-02,  7.5739846e-03,\n",
              "        1.6802121e-02,  4.8079602e-03,  2.3047376e-02, -1.8289804e-02,\n",
              "        2.7891699e-02, -3.5975646e-02,  2.4788644e-02,  4.4871438e-02,\n",
              "       -2.1217620e-02,  1.1372469e-02,  1.3960410e-02,  3.2395963e-02,\n",
              "       -3.6849163e-02, -1.1762798e-02, -4.7865883e-03, -2.9393231e-02,\n",
              "       -1.9905282e-02,  1.3048425e-03, -2.8199935e-02,  1.2134146e-02,\n",
              "       -2.1327330e-02,  4.6346370e-02,  4.9135316e-02, -2.8100109e-02,\n",
              "        2.0910017e-03,  4.9953535e-04,  2.1953810e-02,  4.8466031e-02,\n",
              "        2.6474301e-02, -4.0397633e-02,  2.1278027e-02, -1.4211297e-02,\n",
              "       -2.4194419e-02,  1.2040090e-02,  4.7021676e-02,  1.9030679e-02,\n",
              "        3.3467039e-03,  2.7157929e-02, -2.9261485e-03,  2.2394661e-02,\n",
              "        2.6070062e-02,  5.4167733e-03, -1.8113662e-02,  3.4392465e-02,\n",
              "       -3.0982606e-03,  3.4458924e-02,  1.6970325e-02, -2.5188196e-02,\n",
              "       -3.5344981e-02,  2.6708376e-02,  8.6878613e-04,  4.8003141e-02,\n",
              "        1.1278331e-02, -2.0332718e-02,  4.3428291e-02,  6.4628832e-03,\n",
              "        1.5976299e-02, -1.1386026e-02,  1.5040938e-02,  4.5056764e-02,\n",
              "        2.6280317e-02,  3.2524597e-02, -4.8737314e-02,  4.4052713e-03,\n",
              "        4.3018971e-02, -4.1373514e-02,  3.3153668e-03, -1.1219084e-02,\n",
              "        4.1127946e-02,  2.2849057e-02, -6.8662763e-03,  4.7176704e-03,\n",
              "       -7.0860162e-03, -3.7579048e-02,  3.9310489e-02, -1.0972142e-02,\n",
              "        1.8887926e-02, -6.1289221e-04,  5.0822012e-03, -4.6848416e-02],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These values might not mean much to us but they're what our computer sees each word as. When our model looks for patterns in different samples, these values will be updated as necessary."
      ],
      "metadata": {
        "id": "t3-kE9wjtubc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've got a way to turn our text data into numbers, we can start to build machine learning models to model it.\n",
        "\n",
        "To get plenty of practice, we're going to build a series of different models, each as its own experiment. We'll then compare the results of each model and see which one performed best.\n",
        "\n",
        "More specifically, we'll be building the following:\n",
        "\n",
        "**Model 0:** Naive Bayes (baseline)\n",
        "\n",
        "**Model 1:** Feed-forward neural network (dense model)\n",
        "\n",
        "**Model 2:** LSTM model\n",
        "\n",
        "**Model 3:** GRU model\n",
        "\n",
        "**Model 4:** Bidirectional-LSTM model\n",
        "\n",
        "**Model 5:** 1D Convolutional Neural Network\n",
        "\n",
        "**Model 6:** TensorFlow Hub Pretrained Feature Extractor\n",
        "\n",
        "**Model 7:** Same as model 6 with 10% of training data"
      ],
      "metadata": {
        "id": "RYCAndtKt1pW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 0**\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "\n",
        "- Construct the Model\n",
        "- Train the Model\n",
        "- Maker Predictions with the Model\n",
        "- Track Prediction Evaluation Metrics for Later Comparison\n",
        "\n",
        "**Model 0: Getting a baseline**\n",
        "\n",
        "In all Machine Learning modelling experiments, it is important to **create a baseline ** model, so that we can benchmark against it.\n",
        "\n",
        "To create our baseline, we'll create a **Scikit-Learn Pipeline** using the **TF-IDF (term frequency-inverse document frequency) formula** to convert our words to numbers and then model them with the **Multinomial Naive Bayes algorithm.** This was chosen via referring to the Scikit-Learn machine learning map.\n"
      ],
      "metadata": {
        "id": "xhFYnBRSuTtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "2BOLfXI7bevb",
        "outputId": "8b1688c5-9555-48bd-8c8b-8e5e1cd74484"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>TfidfVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\">?<span>Documentation for TfidfVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>TfidfVectorizer()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate our model and find our baseline metric."
      ],
      "metadata": {
        "id": "umkJE91wwQlv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4cK5MEybesr",
        "outputId": "c4d231dd-b4bb-4158-f824-a801c4606d7d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do some **predictions** with our baseline model"
      ],
      "metadata": {
        "id": "kVy1BrI8wXo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZC0Uw8dbeps",
        "outputId": "3100d5b4-e1da-4be2-f4d2-72995a9a567c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating an Evaluation Function for our Model Experiments**\n",
        "\n",
        "- We are going to create this **function** because we are going to **evaluate several models** in the same way going forward.\n",
        "- Let's create a helper function which takes **an array of predictions and ground truth labels** and compute the following\n",
        "    - Accuracy\n",
        "    - Precision\n",
        "    - Recall\n",
        "    - F1-Score\n",
        "\n",
        "Hence, we are dealing with a **Classification Problem** above metrics are appropriate. If we are dealing with **Regression Problem**, we will use metrics like **MAE (Mean Absolute Error)**"
      ],
      "metadata": {
        "id": "T7gJkndPwhh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "metadata": {
        "id": "2OP2Yrcdbel4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_PMlLJrbedW",
        "outputId": "79378e88-1aa1-4bbb-f391-29e71848969c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 1: A simple Dense Model**\n",
        "\n",
        "The first **deep** model we are going to build is a **single layer dense model**. And\n",
        "\n",
        "- It will take our **text** and **labels** as input\n",
        "- **Tokenize** the **text**\n",
        "- Create and **embedding**\n",
        "- Find the average of **embedding (using Global Average Pooling)** and then pass the average through **fully connected layer** with one output and a **sigmoid** activation.\n",
        "\n",
        "And since we're going to be building a number of TensorFlow deep learning models, we'll import our **create_tensorboard_callback()** function from helper_functions.py to keep track of the results of each.\n"
      ],
      "metadata": {
        "id": "0sBAZorkzMoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "9EzSJJnfzQKE"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "# inputs are 1-dimensional strings\n",
        "\n",
        "x = text_vectorizer(inputs)\n",
        "# turn the input text into numbers\n",
        "\n",
        "x = embedding(x)\n",
        "# create an embedding of the numerized numbers\n",
        "\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "# lower the dimensionality of the embedding\n",
        "# (try running the model without this layer and see what happens)\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "# create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n",
        "# construct the model\n"
      ],
      "metadata": {
        "id": "3-1QwFQ5zQoA"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "The Sequential API code is\n",
        "\n",
        "from tensorflow.keras import Sequential, layers\n",
        "\n",
        "model_1_seq = Sequential([\n",
        "    layers.Input(shape=(1,), dtype=\"string\"),\n",
        "    text_vectorizer,                      # convert text → numbers\n",
        "    embedding,                            # convert numbers → meaning vectors\n",
        "    layers.GlobalAveragePooling1D(),      # summarize each sentence\n",
        "    layers.Dense(1, activation=\"sigmoid\") # output: binary classification\n",
        "], name=\"model_1_dense_sequential\")\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "1Jj9BblYNBS8",
        "outputId": "a72eb089-3a64-4613-8d78-44b3dec5da4d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe Sequential API code is\\n\\nfrom tensorflow.keras import Sequential, layers\\n\\nmodel_1_seq = Sequential([\\n    layers.Input(shape=(1,), dtype=\"string\"),\\n    text_vectorizer,                      # convert text → numbers\\n    embedding,                            # convert numbers → meaning vectors\\n    layers.GlobalAveragePooling1D(),      # summarize each sentence\\n    layers.Dense(1, activation=\"sigmoid\") # output: binary classification\\n], name=\"model_1_dense_sequential\")\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's discuss the code above\n",
        "\n",
        "- Our model takes a **1-dimensional string as input**.\n",
        "- It then tokenizes the string using **text_vectorizer** and creates an **embedding**\n",
        "- By using **GlobalAveragePooling1D()** layer we reduce the dimensionality of the tensor we pass to the **output layer.**"
      ],
      "metadata": {
        "id": "ebAS0enOLJGB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "E70_Mhi6zQk-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "7dsIDofCzQh_",
        "outputId": "c6105391-506c-43b9-8f4b-1029dcf65cc4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_1_dense\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_1_dense\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_average_pooling1d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,280,129\u001b[0m (4.88 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,129</span> (4.88 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,280,129\u001b[0m (4.88 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,129</span> (4.88 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Most of the trainable parameters are contained within the **embedding layer**. Recall we created an embedding of size **128 (output_dim=128)** for a vocabulary of size **10,000** (input_dim=10000), hence the **1,280,000** trainable parameters."
      ],
      "metadata": {
        "id": "Hu2_0Hx6N3y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in model\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T-ItZtfzQWx",
        "outputId": "92a1de2e-9e78-4e79-859b-4caff3a623ba"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20251009-110718\n",
            "Epoch 1/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.6374 - loss: 0.6494 - val_accuracy: 0.7559 - val_loss: 0.5338\n",
            "Epoch 2/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8088 - loss: 0.4660 - val_accuracy: 0.7861 - val_loss: 0.4740\n",
            "Epoch 3/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8530 - loss: 0.3619 - val_accuracy: 0.7953 - val_loss: 0.4621\n",
            "Epoch 4/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8870 - loss: 0.2956 - val_accuracy: 0.7887 - val_loss: 0.4684\n",
            "Epoch 5/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9069 - loss: 0.2468 - val_accuracy: 0.7795 - val_loss: 0.4843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0ZtOjQ8zQTW",
        "outputId": "2f21eac2-c86f-40b7-d4c4-fa2301040911"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7684 - loss: 0.5165\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4842676818370819, 0.7795275449752808]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What **embedding.weights** gives you\n",
        "\n",
        "\n",
        "\n",
        "Returns a list of all the trainable weights in that layer.\n",
        "\n",
        "For a standard embedding layer, there’s usually only one matrix, so the list has one element.\n",
        "\n",
        "Shape: (vocab_size, embedding_dim) → (5000, 128) in our example"
      ],
      "metadata": {
        "id": "piLGL9QyPhjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEalPuTOzQQG",
        "outputId": "03a3c5d6-b838-4f31-e944-67ebea77a7e1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<Variable path=embedding_1/embeddings, shape=(10000, 128), dtype=float32, value=[[-0.01325036  0.0211815  -0.01513357 ... -0.05524667  0.04565595\n",
              "   -0.01864273]\n",
              "  [ 0.03761405  0.01036259 -0.00125246 ...  0.02195662 -0.0276198\n",
              "   -0.00208184]\n",
              "  [ 0.03693467 -0.01538322 -0.00384381 ... -0.0255676   0.03773013\n",
              "   -0.02904656]\n",
              "  ...\n",
              "  [ 0.01115602 -0.00955745  0.00068473 ... -0.02583609  0.01994188\n",
              "   -0.01180987]\n",
              "  [-0.01268602  0.06382184  0.0853771  ... -0.07023269  0.02309494\n",
              "   -0.02182389]\n",
              "  [ 0.09210607  0.1089362   0.05232262 ... -0.07559539  0.10191818\n",
              "   -0.03709696]]>]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**shape=(10000, 128):-** The *10000* is the vocabulary items and *128* is the dimensions for each word."
      ],
      "metadata": {
        "id": "m_faX1FwfK9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_weights = model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embed_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uq44P02ObKA",
        "outputId": "da560380-fb8a-4527-f58f-c4eaa0cd6d1d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recurrent Neural Networks (RNN's)**\n",
        "\n",
        "We will use a special kind of Neural Networks **Recurrent Neural Network (RNN)** for text data.\n",
        "\n",
        "- **RNN:** Use information from **past** helps you with **future**. Take an input **X** and compute **y** based on all previous inputs.\n",
        "\n",
        "- The concept is helpful when dealing with **Sequence data** such as passages of natural language text such as Text\n",
        "\n",
        "- When you read a sentence, you take into account the context of previous words when **deciphering the meaning** of the current word\n",
        "\n",
        "- When an RNN looks at a sequence of text (already in numerical form), the patterns it learns are continually updated based on the order of the sequence.\n",
        "\n",
        "**Recurrent neural networks** can be used for a number of sequence-based problems:\n",
        "\n",
        "- **One to one:** one input, one output, such as image classification.\n",
        "- **One to many:** one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "- **Many to one:** many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "- **Many to many:** many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "\n",
        "- Long short-term memory cells (LSTMs).\n",
        "- Gated recurrent units (GRUs).\n",
        "- Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KzCfsNKzfmFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 2: LSTM**\n",
        "\n",
        "We will start with **LSTM powered RNN**\n",
        "\n",
        "- LSTM Cell and LSTM layer are often used interchangably. We will use **tensorflow.keras.layers.LSTM()**\n",
        "\n",
        "Our model is going to take on a very similar structure to model_1:\n",
        "\n",
        "**Input (text)** -> Tokenize -> Embedding -> Layers -> **Output (label probability)**\n",
        "\n",
        "\n",
        "The main difference will be that we're going to **add an LSTM layer** between our **embedding** and **output.**\n",
        "\n",
        "**Note:-** Make sure not to re-use the **trained embeddings** and we will create another **embedding layer** *model_2_embedding* for our model. The **text_vectorizer** layer can be reused since it does not get updated during training.\n",
        "- Think of **embedding** as a notebook that stores the meaning of words considering the context.\n",
        "- If both models use the **same embedding layer**, then it is like reading from the same book.\n",
        "- This is called **data leakage**\n",
        "\n",
        "*An embedding layer starts with random numbers like the Word2Vec or GloVE. Each word is represented by a vector - a list of numbers that the model will learn to adjust to capture the meaning. For example, when a model sees \"The cat sat on the mat\", it makes predictions, compares them with the correct answers, and **adjusts the embedding layers** to reduce the error.Over the time, the embeddings for words like \"cate\" and \"dog\" start to become **closer in meaning** while \"cat\" and \"banana\" stay far apart.*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BIZ3Sn8yzU8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**\n",
        "\n",
        "- An inherent problem with **RNNs** is that they can forget what happened many steps ago because when **Gradients are propagated through many time steps** they vanish. This means that long-term dependencies are lost.\n",
        "\n",
        "An **LSTM** is a special kind of RNN that remembers information for longer periods using a clever internal structure called a **cell state**.\n",
        "\n",
        "It uses gates to control information flow:\n",
        "\n",
        "- **Forget Gate** → what to throw away\n",
        "- **Input Gate** → what new info to store\n",
        "- **Cell State** → memory itself\n",
        "- **Output Gate** → what to send out\n",
        "\n",
        "**Inside the LSTM Cell**\n",
        "At each step (t), we have:\n",
        "- Input vector xt\n",
        "- Previous hidden state ht-1\n",
        "- Previous cell state ct-1\n",
        "The **LSTM** updates them to produce:\n",
        "- New Cell State ct\n",
        "- New hidden state ht\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LQFSoss2bdta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Set random seed and create embedding layer\n",
        "    (new embedding layer for each model)\n",
        "'''\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "\n",
        "# Create LSTM Model\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True\n",
        "x = layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P0vdGvORObHC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a5bdc4-9521-4825-f1d6-c44264c17f5a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Input:**\n",
        "You have a sentence/tweet of 15 words.\n",
        "\n",
        "**2. Embedding Layer:**\n",
        "Each word is converted to a 128-dimensional vector (embedding).\n",
        "So now your input looks like a matrix of shape:\n",
        "**(15 words, 128 dimensions)**\n",
        "\n",
        "**LSTM Layer (64 units):**\n",
        "\n",
        "Each of the 64 LSTM cells processes the whole sequence of 15 embeddings.\n",
        "Internally, each LSTM cell keeps track of memory through the sequence using gates (forget, input, output).\n",
        "\n",
        "After processing the sequence, the LSTM layer outputs a single 64-dimensional vector (because return_sequences=False), summarizing the entire sentence.\n",
        "\n",
        "**Dense Layer:**\n",
        "\n",
        "The 64-dimensional vector goes into a single Dense unit with sigmoid activation.\n",
        "Sigmoid squashes the output to 0–1, representing the probability of the sentence being positive or negative.\n",
        "\n",
        "\n",
        "Sentence (15 words)\n",
        "     ↓\n",
        "\n",
        "Embeddings (15 × 128)\n",
        "     ↓\n",
        "\n",
        "LSTM (64 units)\n",
        "     ↓\n",
        "    \n",
        "Vector summarizing sentence (64 numbers)\n",
        "     ↓\n",
        "\n",
        "Dense layer (1 output)\n",
        "     ↓\n",
        "\n",
        "Probability: Positive or Negative\n",
        "\n"
      ],
      "metadata": {
        "id": "_Oa1irkc4TcG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:**\n",
        "\n",
        "Reading the documentation for the **TensorFlow LSTM layer**, you'll find a plethora of parameters. Many of these have been tuned to make sure they compute as fast as possible. The main ones you'll be looking to adjust are units **(number of hidden units)** and **return_sequences** (**set this to True **when stacking LSTM or other recurrent layers)."
      ],
      "metadata": {
        "id": "JBa2x1iT5Ydq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compile model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "DwB_VloMObDh"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "id": "7BdVNwnIOa5g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "d948e03b-eb40-479f-8c72-d6732ade77ed"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_2_LSTM\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_2_LSTM\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m49,408\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,329,473\u001b[0m (5.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,473</span> (5.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,329,473\u001b[0m (5.07 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,329,473</span> (5.07 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPUfoblcbeoW",
        "outputId": "6553b3a4-b94a-4930-90d1-fc2315e32365"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20251009-110734\n",
            "Epoch 1/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.6753 - loss: 0.5800 - val_accuracy: 0.7795 - val_loss: 0.4600\n",
            "Epoch 2/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.8633 - loss: 0.3289 - val_accuracy: 0.7585 - val_loss: 0.5105\n",
            "Epoch 3/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9145 - loss: 0.2262 - val_accuracy: 0.7572 - val_loss: 0.6181\n",
            "Epoch 4/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9436 - loss: 0.1576 - val_accuracy: 0.7480 - val_loss: 0.6738\n",
            "Epoch 5/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - accuracy: 0.9622 - loss: 0.1205 - val_accuracy: 0.7717 - val_loss: 0.6166\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1R4dIpMbfL6",
        "outputId": "10a5ee5d-a8dc-4c6f-d93d-3d01ca233008"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.24991111],\n",
              "        [0.95657367],\n",
              "        [0.99856645],\n",
              "        [0.02831087],\n",
              "        [0.00459421],\n",
              "        [0.9809498 ],\n",
              "        [0.73174715],\n",
              "        [0.9979942 ],\n",
              "        [0.9989453 ],\n",
              "        [0.38142493]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can turn **these probabilities** into **prediction classes** by rounding to the nearest integer (By default **prediction probabilities** under 0.5 will go to 0 and those above 0.5 will go to 1)"
      ],
      "metadata": {
        "id": "92xdCXXhmjlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model_2_pred_probs output like\n",
        "\n",
        "                     [   [0.8],\n",
        "                         [0.3],\n",
        "                         [0.9]  ]\n",
        "The **round** function changes it to\n",
        "\n",
        "                [     [1],\n",
        "                      [0],\n",
        "                      [1]   ]\n",
        "\n",
        "The **squeeze** function removes the extra dimensions\n",
        "\n",
        "[1,0,1]"
      ],
      "metadata": {
        "id": "yyBAATTfnSAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u22z4leRbfC7",
        "outputId": "c00fddae-9eb7-4bf9-d187-c31f82921bdf"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c06SOgRbigoh",
        "outputId": "6c0e49f3-9d2c-4b8d-d845-3ef77f002cb5"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'precision': 0.7747861668850706,\n",
              " 'recall': 0.7716535433070866,\n",
              " 'f1': 0.7688960790251899}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key, value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")"
      ],
      "metadata": {
        "id": "RoQHShLwozBw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model 2 to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ06kn0rigfY",
        "outputId": "6aaf0403-347b-4de1-c217-953ea9b9f994"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.17, Difference: -2.10\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 3: Bidirectional RNN Model**\n",
        "\n",
        "Another very popular model is **GRU** or **Gated Recurrent Unit**\n",
        "- **GRU** has similar features to an LSTM cell but has less parameters\n",
        "- To use **GRU** cell in TensorFlow we can call the **tensorflow.keras.layers.GRU()**\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "*Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)*"
      ],
      "metadata": {
        "id": "qSl8FPEVpqbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model_3_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_3\")\n",
        "# Build an RNN using the GRU Cell\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True)\n",
        "x = layers.GRU(64)(x)\n",
        "\n",
        "# x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# optional dense layer after GRU cell\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIooKwg1igWd",
        "outputId": "3f9e2446-76fc-49a2-a418-5ce9fc6974d2"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "35F3wJWvigMc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "qirJJxlgpwzF",
        "outputId": "ac085d52-212a-4cf3-b435-4da01f32ea32"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_3_GRU\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_3_GRU\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m37,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,317,313\u001b[0m (5.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,317,313</span> (5.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,317,313\u001b[0m (5.03 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,317,313</span> (5.03 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Notice the difference in **number of trainable parameters** between **model_2(LSTM)** and **model_3 (GRU)**\n",
        "- The main difference comes from **LSTM Cell** having more trainable parameters than a **GRU Cell.**\n",
        "\n",
        "- We'll fit our model just as we've been doing previously. We'll also track our models results using our **create_tensorboard_callback()** function."
      ],
      "metadata": {
        "id": "65A-Vo5IrcBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRU Theory**\n",
        "\n",
        "- **RNN** has a problem that **it forgets long term information** also called **vanishing gradient problem.**\n",
        "- **GRU** is a simplest form of **LSTM** which can help us with long term information rememberance\n",
        "\n",
        "**Imagine you’re reading a story:**\n",
        "\n",
        "“The man put the milk in the fridge because it was hot.”\n",
        "When you read the word **“it”**, your brain remembers that **“it”** refers to **“milk”** — something you read several words earlier.\n",
        "That’s long-term dependency.\n",
        "\n",
        "*GRU helps a neural network decide how much of the past to remember and how much to forget, just like your brain.*\n",
        "\n",
        "It does this using two gates\n",
        "- **Update Gate (z):** Decides how much of the past to keep\n",
        "- **Reset Gate (r):** Decides how much of the past to forget\n",
        "\n",
        "At each step 't'(for each word or data point in sequence)\n",
        "- Take the current input xt\n",
        "- Take the previous hidden state ht-1\n",
        "- Compute\n",
        "  updated gate:zt= σ(Wz​⋅[ht−1​,xt​])\n",
        "\n",
        "  Reset gate:rt= σ(Wr​⋅[ht−1​,xt​])\n",
        "  \n",
        "  Candidate Memory:\n",
        "          ht=tanh(Wh​⋅[rt​∗ht−1​,xt​])\n",
        "\n",
        "**Blend the Info**\n",
        "\n",
        "        ht​=(1−zt​)∗ht−1​+zt​∗h~t\n",
        "\n",
        "**Why GRU is Popular**\n",
        "\n",
        "✅ Easier to train than LSTM (fewer gates, fewer parameters)\n",
        "✅ Works well on smaller datasets\n",
        "✅ Faster and simpler while still capturing long-term dependencies\n",
        "\n",
        "- **Gates:** LSTM (Input, forget, output) while GRU (update, reset)\n",
        "- **Memory Cell:** LSTM has memory cell while GRU does not have it\n",
        "- **Speed:** LSTM is slower while GRU is faster\n",
        "- **Accuracy:** Often similar\n",
        "- **Complexity:** LSTM has high complexity while GRU is Moderate.\n"
      ],
      "metadata": {
        "id": "S4h9-jC4xIvP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dYWaRGApx4j",
        "outputId": "676dbc4b-d945-4218-d2e6-050ebe056448"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20251009-110807\n",
            "Epoch 1/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - accuracy: 0.6509 - loss: 0.6006 - val_accuracy: 0.7769 - val_loss: 0.4562\n",
            "Epoch 2/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - accuracy: 0.8624 - loss: 0.3341 - val_accuracy: 0.7625 - val_loss: 0.5111\n",
            "Epoch 3/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.9110 - loss: 0.2328 - val_accuracy: 0.7612 - val_loss: 0.5913\n",
            "Epoch 4/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9380 - loss: 0.1719 - val_accuracy: 0.7638 - val_loss: 0.6025\n",
            "Epoch 5/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 45ms/step - accuracy: 0.9596 - loss: 0.1322 - val_accuracy: 0.7598 - val_loss: 0.6520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAlILILVpxvR",
        "outputId": "2a97ba8f-623d-4f11-abe7-a8a8499a9c73"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.0585444 ],\n",
              "        [0.93690646],\n",
              "        [0.994304  ],\n",
              "        [0.10785145],\n",
              "        [0.01040519],\n",
              "        [0.99212456],\n",
              "        [0.19128388],\n",
              "        [0.99574375],\n",
              "        [0.9955693 ],\n",
              "        [0.8610971 ]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zndd-w55pxj4",
        "outputId": "cd59a5b2-5075-4e8c-d56f-ee74906bbe24"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BELAuydOpxbH",
        "outputId": "1fb28dbd-9f05-4745-9a94-a8b461812828"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.98425196850394,\n",
              " 'precision': 0.7637560697167074,\n",
              " 'recall': 0.7598425196850394,\n",
              " 'f1': 0.7563819709955472}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc2vIthNpxT3",
        "outputId": "274c9131-d030-43f5-97e1-448e89f22e29"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.98, Difference: -3.28\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 4: Bidirectional RNN Model**\n",
        "\n",
        "- A standard **RNN** will process a **sequence from left to right**, whereas a **bidrectional RNN** will process the sequence from **left to right** and then again from **right to left**\n",
        "- It's like reading a sentence normally from **left to right** and to make full understanding read it from **right to left** again\n",
        "\n",
        "*In practice, many sequence models often see an improvement in performance when using bidirectional RNN's.*\n",
        "\n",
        "However, this improvement in performance often comes at the** cost of longer training times and increased model parameters **(since the model goes left to right and right to left, the number of trainable parameters doubles).\n",
        "\n",
        "**TensorFlow** helps by providing the **tensorflow.keras.layers.Bidirectional** class. We can use the **Bidirectional** class to wrap our existing RNNs, instantly making them **bidrectional**"
      ],
      "metadata": {
        "id": "N_MSdmDa38GN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_4\")\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)\n",
        "\n",
        "''' x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "        stacking RNN layers requires return_sequences=True'''\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "''' bidirectional goes both ways so has double the parameters of a\n",
        "    regular LSTM layer'''\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsEOs59rpxQo",
        "outputId": "a90f2c82-84a6-4293-aff7-69d087e1ec19"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** You can use the **Bidirectional** wrapper on any **RNN Cell in TensorFlow**. For example, **layers.Bidirectional(layers.GRU(64))** creates a **bidirectional GRU cell.**"
      ],
      "metadata": {
        "id": "nqCA5xvA7d1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "1puSDBYLpxNX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "YsDrpN9jpxFf",
        "outputId": "5fd3b83d-47b2-4df9-8a56-11f218f91119"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_4_Bidirectional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_4_Bidirectional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_4 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m98,816\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,816</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,378,945\u001b[0m (5.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,378,945</span> (5.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,378,945\u001b[0m (5.26 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,378,945</span> (5.26 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the **increased number of trainable parameters** in model_4 (bidirectional LSTM) compared to **model_2 (regular LSTM)**. This is due to the bidirectionality we added to our RNN.\n",
        "\n",
        "**Time to fit our bidirectional model** and track its performance."
      ],
      "metadata": {
        "id": "cLu-bNdt7_cR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"bidirectional_RNN\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BekXufqtw1nZ",
        "outputId": "8c04ae8b-7e9a-424b-b75a-2acced1db3bd"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20251009-110842\n",
            "Epoch 1/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.6775 - loss: 0.5814 - val_accuracy: 0.7769 - val_loss: 0.4608\n",
            "Epoch 2/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 30ms/step - accuracy: 0.8653 - loss: 0.3274 - val_accuracy: 0.7717 - val_loss: 0.5058\n",
            "Epoch 3/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 32ms/step - accuracy: 0.9167 - loss: 0.2218 - val_accuracy: 0.7493 - val_loss: 0.6033\n",
            "Epoch 4/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 31ms/step - accuracy: 0.9471 - loss: 0.1459 - val_accuracy: 0.7533 - val_loss: 0.6587\n",
            "Epoch 5/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 35ms/step - accuracy: 0.9622 - loss: 0.1151 - val_accuracy: 0.7428 - val_loss: 0.7429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Due to the bidirectionality of our model we see a slight increase in training time."
      ],
      "metadata": {
        "id": "4aZ36gLMBWYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with bidirectional RNN on the validation data\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW_lPkuWw1d6",
        "outputId": "f3c13b31-34c1-4c77-f314-86abc1ce2745"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11086708],\n",
              "       [0.988601  ],\n",
              "       [0.9996399 ],\n",
              "       [0.07283685],\n",
              "       [0.00842149],\n",
              "       [0.9950955 ],\n",
              "       [0.84937453],\n",
              "       [0.9998815 ],\n",
              "       [0.99890023],\n",
              "       [0.53743035]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "id": "aqE03wwc7dSB",
        "outputId": "b87cf0d3-0a53-4034-ddb7-940dc075e437",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "id": "kC4bT3rs7dJI",
        "outputId": "f191a862-4d99-4800-bab9-f1afe6cdc36a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 74.2782152230971,\n",
              " 'precision': 0.7436694999217812,\n",
              " 'recall': 0.7427821522309711,\n",
              " 'f1': 0.7404494883483694}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "id": "PtvuXXm1BmM4",
        "outputId": "446da2e9-205b-4a36-d231-06e525d51868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 74.28, Difference: -4.99\n",
            "Baseline precision: 0.81, New precision: 0.74, Difference: -0.07\n",
            "Baseline recall: 0.79, New recall: 0.74, Difference: -0.05\n",
            "Baseline f1: 0.79, New f1: 0.74, Difference: -0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convolutional Neural Networks For Text**\n",
        "\n",
        "- You might've used convolutional neural networks (CNNs) for images before but they can also be used for sequences.\n",
        "\n",
        "- The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "- So to use CNNs with sequences, we use a 1-dimensional convolution instead of a 2-dimensional convolution.\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n",
        "\n",
        "\n",
        "The difference again is in the layers component. Instead of using an LSTM or GRU cell, we're going to use a **tensorflow.keras.layers.Conv1D() layer** followed by a **tensorflow.keras.layers.GlobablMaxPool1D() layer.**\n",
        "\n",
        "\n",
        "- 1 dimensional convolving filters are used as ngram detectors, each filter specializing in a closely-related family of ngrams (an ngram is a collection of n-words, for example, an ngram of 5 might result in \"hello, my name is Daniel\").\n",
        "- 2 Max-pooling over time extracts the relevant ngrams for making a decision.\n",
        "\n",
        "- 3 The rest of the network classifies the text based on this information.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OjltIQYpBuFI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 5: Conv1D**\n",
        "\n",
        "Before building a full **1-dimensional CNN Model** let's see a **1-dimensional Convolution Layer** also called **Temporal Convolution** in action.\n",
        "\n",
        "We will first create an embedding of a sample of text and experiment passing it through **Conv1D()** layer and **GlobalMaxPoolID()** layer."
      ],
      "metadata": {
        "id": "uva1uvQ8CnsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding, 1D Convolutional and max pooling\n",
        "\n",
        "# Turn the target sentence into embedding\n",
        "embedding_test = embedding(text_vectorizer([\"This is a test sentence\"]))\n",
        "conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")\n",
        "conv_1d_output = conv_1d(embedding_test)\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output)\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape\n",
        "\n"
      ],
      "metadata": {
        "id": "SHMmwmvYBmCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "639a74c0-268e-41ed-d393-d7136ea160c1"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **embedding_test:-** Converts the text into a tensor of shape ([1,15,128]) where '1' is the batch info, '15' is the input length and each word in the sentence is converted to '128' dimensions vector.\n",
        "\n",
        "- **conv_1d = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")** This is a **pattern detector** sliding over your sentence.\n",
        "    - **kernel_size=5** means that the convolution looks at **5 words at a time**. For example, *This is a test sentence* is checked like first *This is a test* and then *is a test sentence*\n",
        "- **filter=32:** means we have **32 detectors** (each trying to find a different type of word pattern). **It is like having 32 detectors each looking for different patterns like 'positive tone' and other might detect 'negative tone'. The sentence length becomes (1,11,32). 1 is the sentence in batch, 11 is the number of positions(word windows) the convolution moved across and 32 is the Number of filters(pattern detectors)\n",
        "\n",
        "What the convolution actually did\n",
        "\n",
        "Let’s say your sentence (after embedding)\n",
        "had 15 words → shape (1, 15, 128)\n",
        "\n",
        "Now your convolution is set with kernel_size=5 → looks at 5 words at a time.\n",
        "\n",
        "*The convolution starts at word 1–5, then slides to words 2–6, then 3–7, etc.\n",
        "So, how many such windows does it get?*\n",
        "\n",
        "👉 15 (words) − 5 (window) + 1 = 11 windows\n",
        "\n",
        "That’s why you see 11 as the second number in (1, 11, 32).\n",
        "\n",
        "Each window (chunk of 5 words) gets processed by 32 filters —\n",
        "so you get 32 output numbers per window, showing how strongly each filter responded to that chunk.\n",
        "\n",
        "Input sentence (15 words)\n",
        "\n",
        "↓\n",
        "\n",
        "Convolution with window=5 slides 11 times\n",
        "\n",
        "↓\n",
        "\n",
        "Each slide produces 32 numbers (from 32 filters)\n",
        "\n",
        "↓\n",
        "\n",
        "Resulting output → (1, 11, 32)\n",
        "\n",
        "- **max_pool = layers.GlobalMaxPool1D()**\n",
        "We’re starting with the conv_1d_output of shape:\n",
        "(1, 11, 32) → which means:\n",
        "- 1 = one sentence (batch size)\n",
        "- 11 = 11 sliding windows (5-word chunks)\n",
        "- 32 = 32 filters (each finding a pattern)\n",
        "\n",
        "For each of the 32 filters (pattern detectors), find the strongest signal across all 11 chunks.\n",
        "\n",
        "It “summarizes” each filter’s responses by keeping only its maximum value — the one where it responded most strongly."
      ],
      "metadata": {
        "id": "HftZTnI4tzdF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An intutive way of understanding above**\n",
        "\n",
        "- Each sentence is **15 words**, and each word is represented by **128 numbers** so the shape is *(15, 128)*, 15 rows and 128 columns with each row representing a word with 128 dimensions.\n",
        "\n",
        "You’ve told the Conv1D layer:\n",
        "\n",
        "- **kernel_size = 5** → look at 5 words at a time\n",
        "- **filters = 32** → use 32 different “pattern detectors”\n",
        "\n",
        "Now the convolution will take **5 rows(words) x 128 columns (embedding dims)** and multiple it by a kernel of **32 kernel**.\n",
        "Since, each word is **128-dim vector**, the window is a small **5 x 128 matrix**\n",
        "\n",
        "Now,\n",
        "- Each **row** of the kernel correponds to a position in the **5-word window.**\n",
        "- Each **column** corresponds to an *embedding feature.*\n",
        "- Each element Kij is a trainable weight.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_TRWEsBW06yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_test.shape\n",
        "embedding_test[:1]"
      ],
      "metadata": {
        "id": "nxRGS4WbBl4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c8536f-68e3-4981-a6c4-ce57844d7a37"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00689882,  0.01558637,  0.04679224, ...,  0.04097068,\n",
              "         -0.0077493 ,  0.03530424],\n",
              "        [ 0.02853888,  0.01967032,  0.02235212, ..., -0.03355449,\n",
              "         -0.01723835, -0.05492988],\n",
              "        [-0.00563933, -0.0075665 , -0.02510787, ...,  0.01567699,\n",
              "         -0.01620559, -0.05446053],\n",
              "        ...,\n",
              "        [-0.01325036,  0.0211815 , -0.01513357, ..., -0.05524667,\n",
              "          0.04565595, -0.01864273],\n",
              "        [-0.01325036,  0.0211815 , -0.01513357, ..., -0.05524667,\n",
              "          0.04565595, -0.01864273],\n",
              "        [-0.01325036,  0.0211815 , -0.01513357, ..., -0.05524667,\n",
              "          0.04565595, -0.01864273]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_1d_output.shape\n",
        "conv_1d_output[:1]"
      ],
      "metadata": {
        "id": "KXR_i-S4BlrA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91bafc0-adb4-41e3-9899-8aaf841fae5b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 11, 32), dtype=float32, numpy=\n",
              "array([[[0.03655996, 0.12613723, 0.        , 0.06870178, 0.09322613,\n",
              "         0.08816093, 0.02233853, 0.        , 0.00532557, 0.        ,\n",
              "         0.        , 0.17987034, 0.        , 0.02863005, 0.13624111,\n",
              "         0.        , 0.08822712, 0.09706487, 0.        , 0.0009329 ,\n",
              "         0.03885968, 0.1387533 , 0.        , 0.04235066, 0.03736172,\n",
              "         0.05846445, 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.        , 0.02259161, 0.        , 0.02077084,\n",
              "         0.01890488, 0.        , 0.10071232, 0.        , 0.06708212,\n",
              "         0.05403037, 0.        , 0.07743414, 0.        , 0.13780522,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "         0.        , 0.02061899, 0.03057478, 0.02854359, 0.        ,\n",
              "         0.03003151, 0.        , 0.00337284, 0.04962951, 0.00481275,\n",
              "         0.        , 0.        ],\n",
              "        [0.        , 0.02430483, 0.        , 0.02591959, 0.        ,\n",
              "         0.        , 0.        , 0.01517485, 0.        , 0.        ,\n",
              "         0.        , 0.01803249, 0.        , 0.        , 0.13351743,\n",
              "         0.        , 0.        , 0.00652826, 0.        , 0.0559021 ,\n",
              "         0.02240295, 0.        , 0.        , 0.08548732, 0.        ,\n",
              "         0.07523859, 0.        , 0.04437537, 0.        , 0.        ,\n",
              "         0.        , 0.        ],\n",
              "        [0.03880952, 0.        , 0.01956223, 0.01672622, 0.09422453,\n",
              "         0.        , 0.        , 0.07719976, 0.        , 0.06879163,\n",
              "         0.        , 0.        , 0.06387286, 0.01497196, 0.1872321 ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.01720177,\n",
              "         0.        , 0.06238929, 0.        , 0.01827397, 0.        ,\n",
              "         0.08513152, 0.        , 0.        , 0.        , 0.07850181,\n",
              "         0.03866574, 0.0184381 ],\n",
              "        [0.0296594 , 0.01809704, 0.        , 0.04221155, 0.02522342,\n",
              "         0.        , 0.0107884 , 0.02105039, 0.        , 0.02761883,\n",
              "         0.        , 0.        , 0.00695727, 0.        , 0.06791115,\n",
              "         0.        , 0.02128627, 0.        , 0.00393562, 0.00878351,\n",
              "         0.        , 0.        , 0.        , 0.00558491, 0.02029308,\n",
              "         0.03168036, 0.        , 0.        , 0.03443794, 0.        ,\n",
              "         0.03973806, 0.        ],\n",
              "        [0.06388578, 0.        , 0.        , 0.        , 0.03264812,\n",
              "         0.        , 0.        , 0.05362352, 0.        , 0.02546577,\n",
              "         0.        , 0.        , 0.        , 0.00931257, 0.0609598 ,\n",
              "         0.        , 0.00603794, 0.        , 0.0074542 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.01604493,\n",
              "         0.00022146, 0.        , 0.        , 0.01526043, 0.        ,\n",
              "         0.03939221, 0.        ],\n",
              "        [0.06388578, 0.        , 0.        , 0.        , 0.03264812,\n",
              "         0.        , 0.        , 0.05362352, 0.        , 0.02546577,\n",
              "         0.        , 0.        , 0.        , 0.00931257, 0.0609598 ,\n",
              "         0.        , 0.00603794, 0.        , 0.0074542 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.01604493,\n",
              "         0.00022146, 0.        , 0.        , 0.01526043, 0.        ,\n",
              "         0.03939221, 0.        ],\n",
              "        [0.06388578, 0.        , 0.        , 0.        , 0.03264812,\n",
              "         0.        , 0.        , 0.05362352, 0.        , 0.02546577,\n",
              "         0.        , 0.        , 0.        , 0.00931257, 0.0609598 ,\n",
              "         0.        , 0.00603794, 0.        , 0.0074542 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.01604493,\n",
              "         0.00022146, 0.        , 0.        , 0.01526043, 0.        ,\n",
              "         0.03939221, 0.        ],\n",
              "        [0.06388578, 0.        , 0.        , 0.        , 0.03264812,\n",
              "         0.        , 0.        , 0.05362352, 0.        , 0.02546577,\n",
              "         0.        , 0.        , 0.        , 0.00931257, 0.0609598 ,\n",
              "         0.        , 0.00603794, 0.        , 0.0074542 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.01604493,\n",
              "         0.00022146, 0.        , 0.        , 0.01526043, 0.        ,\n",
              "         0.03939221, 0.        ],\n",
              "        [0.06388578, 0.        , 0.        , 0.        , 0.03264812,\n",
              "         0.        , 0.        , 0.05362352, 0.        , 0.02546577,\n",
              "         0.        , 0.        , 0.        , 0.00931257, 0.0609598 ,\n",
              "         0.        , 0.00603794, 0.        , 0.0074542 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.01604493,\n",
              "         0.00022146, 0.        , 0.        , 0.01526043, 0.        ,\n",
              "         0.03939221, 0.        ],\n",
              "        [0.06388578, 0.        , 0.        , 0.        , 0.03264812,\n",
              "         0.        , 0.        , 0.05362352, 0.        , 0.02546577,\n",
              "         0.        , 0.        , 0.        , 0.00931257, 0.0609598 ,\n",
              "         0.        , 0.00603794, 0.        , 0.0074542 , 0.        ,\n",
              "         0.        , 0.        , 0.        , 0.        , 0.01604493,\n",
              "         0.00022146, 0.        , 0.        , 0.01526043, 0.        ,\n",
              "         0.03939221, 0.        ]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_5\")\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_5_embedding(x)\n",
        "x = layers.Conv1D(filters=32, kernel_size=5, activation=\"relu\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "# Print the summary\n",
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ZSIXvKAdnMWM",
        "outputId": "e05a9df5-5d6f-4c07-f4fe-308c2f16db48"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"model_5_Conv1D\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"model_5_Conv1D\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mTextVectorization\u001b[0m)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_5 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │        \u001b[38;5;34m20,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ text_vectorization_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TextVectorization</span>)             │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ embedding_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,300,545\u001b[0m (4.96 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,300,545</span> (4.96 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,300,545\u001b[0m (4.96 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,300,545</span> (4.96 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Woohoo! Looking great! Notice how the number of trainable parameters for the 1-dimensional convolutional layer is similar to that of the LSTM layer in model_2.\n",
        "\n",
        "Let's fit our 1D CNN model to our text data. In line with previous experiments, we'll save its results using our create_tensorboard_callback() function."
      ],
      "metadata": {
        "id": "tYh8qxas6YcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(\n",
        "                                  SAVE_DIR, \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X21dnVIQnMSb",
        "outputId": "d2694632-b89f-4076-f893-09b33f5e7ffd"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20251009-122023\n",
            "Epoch 1/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.6507 - loss: 0.6239 - val_accuracy: 0.7822 - val_loss: 0.4680\n",
            "Epoch 2/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8460 - loss: 0.3681 - val_accuracy: 0.7874 - val_loss: 0.4760\n",
            "Epoch 3/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - accuracy: 0.9128 - loss: 0.2329 - val_accuracy: 0.7861 - val_loss: 0.5309\n",
            "Epoch 4/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9508 - loss: 0.1488 - val_accuracy: 0.7861 - val_loss: 0.6004\n",
            "Epoch 5/5\n",
            "\u001b[1m215/215\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9663 - loss: 0.1045 - val_accuracy: 0.7822 - val_loss: 0.6521\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with model_5\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujp40FLwnMLj",
        "outputId": "fd9775ff-d4ca-4cde-91b8-37307cad0e01"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.89048654],\n",
              "       [0.89241564],\n",
              "       [0.9999319 ],\n",
              "       [0.1475555 ],\n",
              "       [0.00546581],\n",
              "       [0.9963466 ],\n",
              "       [0.9844464 ],\n",
              "       [0.9991346 ],\n",
              "       [0.999044  ],\n",
              "       [0.2209142 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOb9z8gt6yCk",
        "outputId": "c102eba5-5a22-4091-cbc5-5d850c890a0e"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_5 evaluation metrics\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyXSHW9q6x_s",
        "outputId": "b0e1d5e8-4850-491b-f254-7f4040bcc142"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'precision': 0.7843528649827862,\n",
              " 'recall': 0.7821522309711286,\n",
              " 'f1': 0.7800522271093586}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model_5 results to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYxwATh16x86",
        "outputId": "74f39c35-e78d-4f3b-c0df-e9f8e3dd9b42"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.22, Difference: -1.05\n",
            "Baseline precision: 0.81, New precision: 0.78, Difference: -0.03\n",
            "Baseline recall: 0.79, New recall: 0.78, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Using Pretrained Embeddings (Transfer Learning for NLP)**"
      ],
      "metadata": {
        "id": "_E7g5rtu7LOH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kl1FGPsA6x5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D7Q-swVG6xxt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}